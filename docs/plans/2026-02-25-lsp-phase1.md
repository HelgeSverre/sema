# Sema LSP Phase 1 — Parse Diagnostics + Completion Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Create the `sema-lsp` crate with `tower-lsp`, wire it into the `sema lsp` subcommand, and ship Phase 1 (parse diagnostics) + Phase 2 (completion).

**Architecture:** A new `crates/sema-lsp` crate uses `tower-lsp` for the LSP protocol. A dedicated backend thread owns all `Rc` state (Interpreter, parsed ASTs). Async tower-lsp handlers send requests via `tokio::sync::mpsc` and receive responses via `tokio::sync::oneshot`. Phase 1 provides real-time parse error diagnostics; Phase 2 adds completion for special forms, builtins, and user-defined top-level names.

**Tech Stack:** Rust, tower-lsp 0.20, tokio, dashmap 6, sema-core, sema-reader, sema-eval

---

## Task 1: Create the `sema-lsp` crate skeleton

**Files:**
- Create: `crates/sema-lsp/Cargo.toml`
- Create: `crates/sema-lsp/src/lib.rs`
- Modify: `Cargo.toml` (workspace root — add member + dependencies)

**Step 1: Create `crates/sema-lsp/Cargo.toml`**

```toml
[package]
name = "sema-lsp"
version.workspace = true
edition.workspace = true
license.workspace = true
repository.workspace = true
homepage.workspace = true
description = "Language Server Protocol server for Sema"

[dependencies]
sema-core.workspace = true
sema-reader.workspace = true
sema-eval.workspace = true
tower-lsp.workspace = true
tokio = { workspace = true, features = ["rt-multi-thread", "macros", "io-std", "sync"] }
dashmap.workspace = true
serde.workspace = true
serde_json.workspace = true
```

**Step 2: Create `crates/sema-lsp/src/lib.rs`**

Minimal stub that compiles:

```rust
use tower_lsp::jsonrpc::Result;
use tower_lsp::lsp_types::*;
use tower_lsp::{Client, LanguageServer, LspService, Server};

pub async fn run_server() {
    let stdin = tokio::io::stdin();
    let stdout = tokio::io::stdout();
    let (service, socket) = LspService::new(|client| Backend::new(client));
    Server::new(stdin, stdout, socket).serve(service).await;
}

struct Backend {
    client: Client,
}

impl Backend {
    fn new(client: Client) -> Self {
        Backend { client }
    }
}

#[tower_lsp::async_trait]
impl LanguageServer for Backend {
    async fn initialize(&self, _: InitializeParams) -> Result<InitializeResult> {
        Ok(InitializeResult {
            capabilities: ServerCapabilities {
                text_document_sync: Some(TextDocumentSyncCapability::Kind(
                    TextDocumentSyncKind::FULL,
                )),
                ..Default::default()
            },
            ..Default::default()
        })
    }

    async fn shutdown(&self) -> Result<()> {
        Ok(())
    }
}
```

**Step 3: Add to workspace**

In root `Cargo.toml`:
- Add `"crates/sema-lsp"` to `workspace.members`
- Add workspace dependencies: `tower-lsp = "0.20"`, `dashmap = "6"`

**Step 4: Verify it compiles**

Run: `cargo build -p sema-lsp`
Expected: compiles with no errors

**Step 5: Commit**

```bash
git add crates/sema-lsp/ Cargo.toml Cargo.lock
git commit -m "feat(lsp): create sema-lsp crate skeleton with tower-lsp"
```

---

## Task 2: Wire `sema lsp` subcommand

**Files:**
- Modify: `crates/sema/Cargo.toml` (add `sema-lsp` dependency)
- Modify: `crates/sema/src/main.rs` (add `Lsp` variant to `Commands` enum, add handler)

**Step 1: Add dependency**

In `crates/sema/Cargo.toml`, add under `[dependencies]`:
```toml
sema-lsp = { version = "=1.11.0", path = "../sema-lsp" }
```

Also add `sema-lsp` to `[workspace.dependencies]` in root `Cargo.toml`:
```toml
sema-lsp = { version = "=1.11.0", path = "crates/sema-lsp" }
```

Then in `crates/sema/Cargo.toml` use:
```toml
sema-lsp.workspace = true
```

**Step 2: Add `Lsp` variant to `Commands` enum**

In `crates/sema/src/main.rs`, find the `Commands` enum (line ~271). Add after the last variant (`Eval { ... }`):

```rust
    /// Start the Language Server Protocol server
    Lsp,
```

**Step 3: Add handler in `main()`**

Find the match arm for `Commands::Eval` and add after it:

```rust
Some(Commands::Lsp) => {
    tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .expect("Failed to create tokio runtime")
        .block_on(sema_lsp::run_server());
}
```

Note: Check how the existing code handles tokio. If there's already a `#[tokio::main]` or a runtime builder pattern, follow that convention. The `sema` binary currently uses `tokio::runtime::Runtime` via `block_on` in various places (e.g., LLM calls). The LSP needs a multi-thread runtime.

**Step 4: Verify it compiles and runs**

Run: `cargo build -p sema-lang`
Run: `echo '{"jsonrpc":"2.0","id":0,"method":"initialize","params":{"capabilities":{}}}' | cargo run -- lsp`

The LSP should accept the initialize request and respond (though the pipe will close immediately).

**Step 5: Commit**

```bash
git add crates/sema/Cargo.toml crates/sema/src/main.rs Cargo.toml Cargo.lock
git commit -m "feat(lsp): wire 'sema lsp' subcommand"
```

---

## Task 3: Backend thread + channel architecture

**Files:**
- Modify: `crates/sema-lsp/src/lib.rs`

**Step 1: Define request/response types**

Add channel types for communication between async handlers and the backend thread:

```rust
use tokio::sync::{mpsc, oneshot};
use dashmap::DashMap;
use sema_core::{Caps, Sandbox, Span};

enum BackendRequest {
    /// Document opened or changed — re-parse and return diagnostics
    DocumentChanged {
        uri: Url,
        text: String,
        respond: oneshot::Sender<Vec<Diagnostic>>,
    },
    /// Document closed — clean up
    DocumentClosed {
        uri: Url,
    },
    /// Completion request
    Completion {
        uri: Url,
        position: Position,
        respond: oneshot::Sender<Vec<CompletionItem>>,
    },
}
```

**Step 2: Create the backend thread**

The backend thread owns the `Interpreter` (sandboxed) and caches. It runs a loop receiving `BackendRequest` messages:

```rust
fn spawn_backend(mut rx: mpsc::UnboundedReceiver<BackendRequest>) {
    std::thread::spawn(move || {
        // All Rc state lives on this thread
        let interpreter = sema_eval::Interpreter::new_with_sandbox(
            &Sandbox::deny(Caps::ALL)
        );

        // Collect builtin names once
        let mut builtins: Vec<String> = Vec::new();
        {
            let bindings = interpreter.global_env.bindings.borrow();
            for (spur, _) in bindings.iter() {
                builtins.push(sema_core::resolve(*spur));
            }
        }
        builtins.sort();

        // Document text cache (for completion lookups)
        let mut documents: std::collections::HashMap<Url, String> = std::collections::HashMap::new();

        while let Some(req) = rx.blocking_recv() {
            match req {
                BackendRequest::DocumentChanged { uri, text, respond } => {
                    let diagnostics = compute_diagnostics(&text);
                    documents.insert(uri, text);
                    let _ = respond.send(diagnostics);
                }
                BackendRequest::DocumentClosed { uri } => {
                    documents.remove(&uri);
                }
                BackendRequest::Completion { uri, position, respond } => {
                    let items = compute_completions(
                        documents.get(&uri).map(|s| s.as_str()),
                        position,
                        &builtins,
                    );
                    let _ = respond.send(items);
                }
            }
        }
    });
}
```

**Step 3: Wire Backend into the LSP Backend struct**

```rust
struct Backend {
    client: Client,
    tx: mpsc::UnboundedSender<BackendRequest>,
}

impl Backend {
    fn new(client: Client) -> Self {
        let (tx, rx) = mpsc::unbounded_channel();
        spawn_backend(rx);
        Backend { client, tx }
    }
}
```

**Step 4: Verify it compiles**

Add placeholder functions:
```rust
fn compute_diagnostics(_text: &str) -> Vec<Diagnostic> { vec![] }
fn compute_completions(_text: Option<&str>, _pos: Position, _builtins: &[String]) -> Vec<CompletionItem> { vec![] }
```

Run: `cargo build -p sema-lsp`

**Step 5: Commit**

```bash
git add crates/sema-lsp/src/lib.rs
git commit -m "feat(lsp): backend thread with channel architecture"
```

---

## Task 4: Parse diagnostics (Phase 1 core)

**Files:**
- Modify: `crates/sema-lsp/src/lib.rs`

**Step 1: Implement `span_to_lsp_range`**

```rust
fn span_to_lsp_range(span: &Span) -> Range {
    let start = Position {
        line: span.line.saturating_sub(1) as u32,
        character: span.col.saturating_sub(1) as u32,
    };
    let end = Position {
        line: span.end_line.saturating_sub(1) as u32,
        character: span.end_col.saturating_sub(1) as u32,
    };
    Range { start, end }
}
```

**Step 2: Implement `error_to_diagnostic`**

```rust
use sema_core::SemaError;

fn error_to_diagnostic(err: &SemaError) -> Diagnostic {
    let range = match err.span() {
        Some(span) => span_to_lsp_range(span),
        None => Range::default(),
    };
    let mut message = err.inner().to_string();
    if let Some(hint) = err.hint() {
        message.push_str(&format!("\nhint: {hint}"));
    }
    if let Some(note) = err.note() {
        message.push_str(&format!("\nnote: {note}"));
    }
    Diagnostic {
        range,
        severity: Some(DiagnosticSeverity::ERROR),
        source: Some("sema".into()),
        message,
        ..Default::default()
    }
}
```

**Step 3: Implement `compute_diagnostics`**

Replace the placeholder:

```rust
fn compute_diagnostics(text: &str) -> Vec<Diagnostic> {
    match sema_reader::read_many_with_spans(text) {
        Ok(_) => vec![],
        Err(e) => vec![error_to_diagnostic(&e)],
    }
}
```

**Step 4: Wire didOpen/didChange/didClose handlers**

Add to the `LanguageServer` impl:

```rust
async fn did_open(&self, params: DidOpenTextDocumentParams) {
    let uri = params.text_document.uri.clone();
    let text = params.text_document.text;
    let (tx_resp, rx_resp) = oneshot::channel();
    let _ = self.tx.send(BackendRequest::DocumentChanged {
        uri: uri.clone(),
        text,
        respond: tx_resp,
    });
    if let Ok(diagnostics) = rx_resp.await {
        self.client
            .publish_diagnostics(uri, diagnostics, None)
            .await;
    }
}

async fn did_change(&self, params: DidChangeTextDocumentParams) {
    let uri = params.text_document.uri.clone();
    // Full sync — take the last change
    if let Some(change) = params.content_changes.into_iter().last() {
        let (tx_resp, rx_resp) = oneshot::channel();
        let _ = self.tx.send(BackendRequest::DocumentChanged {
            uri: uri.clone(),
            text: change.text,
            respond: tx_resp,
        });
        if let Ok(diagnostics) = rx_resp.await {
            self.client
                .publish_diagnostics(uri, diagnostics, None)
                .await;
        }
    }
}

async fn did_close(&self, params: DidCloseTextDocumentParams) {
    let uri = params.text_document.uri.clone();
    let _ = self.tx.send(BackendRequest::DocumentClosed { uri: uri.clone() });
    // Clear diagnostics
    self.client
        .publish_diagnostics(uri, vec![], None)
        .await;
}
```

**Step 5: Verify it compiles**

Run: `cargo build -p sema-lsp`

**Step 6: Commit**

```bash
git add crates/sema-lsp/src/lib.rs
git commit -m "feat(lsp): Phase 1 parse diagnostics"
```

---

## Task 5: Completion (Phase 2)

**Files:**
- Modify: `crates/sema-lsp/src/lib.rs`

**Step 1: Add completion capability to `initialize`**

In the `initialize` handler, add to `ServerCapabilities`:

```rust
completion_provider: Some(CompletionOptions {
    trigger_characters: Some(vec!["(".into(), " ".into()]),
    ..Default::default()
}),
```

**Step 2: Implement prefix extraction**

```rust
/// Extract the symbol prefix at a given position from document text.
/// Treats `/`, `-`, `?`, `!`, `>`, `*`, `.` as part of symbols (Sema naming conventions).
fn extract_prefix(text: &str, position: &Position) -> String {
    let line_idx = position.line as usize;
    let col_idx = position.character as usize;
    let line = match text.lines().nth(line_idx) {
        Some(l) => l,
        None => return String::new(),
    };
    let before = &line[..col_idx.min(line.len())];
    let start = before
        .rfind(|c: char| c.is_whitespace() || c == '(' || c == '[' || c == '{' || c == '\'')
        .map(|i| i + 1)
        .unwrap_or(0);
    before[start..].to_string()
}
```

**Step 3: Implement `compute_completions`**

Replace the placeholder:

```rust
use sema_eval::SPECIAL_FORM_NAMES;

fn compute_completions(
    text: Option<&str>,
    position: Position,
    builtins: &[String],
) -> Vec<CompletionItem> {
    let prefix = match text {
        Some(t) => extract_prefix(t, &position),
        None => return vec![],
    };
    if prefix.is_empty() {
        return vec![];
    }

    let mut items = Vec::new();

    // Special forms
    for &sf in SPECIAL_FORM_NAMES {
        if sf.starts_with(&prefix) {
            items.push(CompletionItem {
                label: sf.to_string(),
                kind: Some(CompletionItemKind::KEYWORD),
                ..Default::default()
            });
        }
    }

    // Builtins
    for name in builtins {
        if name.starts_with(&prefix) {
            items.push(CompletionItem {
                label: name.clone(),
                kind: Some(CompletionItemKind::FUNCTION),
                ..Default::default()
            });
        }
    }

    // User-defined top-level names
    if let Some(t) = text {
        if let Ok((exprs, _)) = sema_reader::read_many_with_spans(t) {
            for expr in &exprs {
                if let Some(items_ref) = expr.as_list() {
                    if items_ref.len() >= 2 {
                        let head = items_ref[0].as_symbol();
                        let name = items_ref[1].as_symbol();
                        if let (Some(h), Some(n)) = (head, name) {
                            if n.starts_with(&prefix) {
                                let kind = match h.as_str() {
                                    "defun" | "defmacro" | "defagent" | "deftool" => {
                                        CompletionItemKind::FUNCTION
                                    }
                                    "define" | "def" => CompletionItemKind::VARIABLE,
                                    _ => continue,
                                };
                                items.push(CompletionItem {
                                    label: n.to_string(),
                                    kind: Some(kind),
                                    ..Default::default()
                                });
                            }
                        }
                    }
                }
            }
        }
    }

    items.sort_by(|a, b| a.label.cmp(&b.label));
    items.dedup_by(|a, b| a.label == b.label);
    items
}
```

**Step 4: Wire completion handler**

Add to the `LanguageServer` impl:

```rust
async fn completion(&self, params: CompletionParams) -> Result<Option<CompletionResponse>> {
    let uri = params.text_document_position.text_document.uri;
    let position = params.text_document_position.position;
    let (tx_resp, rx_resp) = oneshot::channel();
    let _ = self.tx.send(BackendRequest::Completion {
        uri,
        position,
        respond: tx_resp,
    });
    match rx_resp.await {
        Ok(items) if !items.is_empty() => {
            Ok(Some(CompletionResponse::Array(items)))
        }
        _ => Ok(None),
    }
}
```

**Step 5: Verify it compiles**

Run: `cargo build -p sema-lsp`

**Step 6: Commit**

```bash
git add crates/sema-lsp/src/lib.rs
git commit -m "feat(lsp): Phase 2 completion for special forms, builtins, and user definitions"
```

---

## Task 6: Integration tests

**Files:**
- Create: `crates/sema-lsp/tests/lsp_test.rs`

**Step 1: Write integration tests**

Use `tower_lsp::LspService::new()` for in-process testing:

```rust
use sema_lsp::run_server;
// For now, test the helper functions directly
use sema_core::Span;

#[test]
fn test_span_to_lsp_range() {
    // Test that 1-indexed Span converts to 0-indexed LSP range
}

#[test]
fn test_diagnostics_valid_code() {
    // Parse valid code → empty diagnostics
}

#[test]
fn test_diagnostics_unclosed_paren() {
    // Parse "(define x" → one diagnostic with error
}

#[test]
fn test_diagnostics_unterminated_string() {
    // Parse "(define x \"hello)" → diagnostic
}

#[test]
fn test_completion_prefix_extraction() {
    // Test prefix extraction at various positions
}

#[test]
fn test_completions_special_forms() {
    // Prefix "def" should match "define", "defun", "defmacro", etc.
}

#[test]
fn test_completions_builtins() {
    // Prefix "string/" should match builtin string functions
}
```

Note: The helper functions (`compute_diagnostics`, `compute_completions`, `span_to_lsp_range`, `extract_prefix`) should be `pub(crate)` or `pub` so they can be tested. Alternatively, test via the public `run_server` API if tower-lsp provides test utilities.

For testability, consider making the core functions `pub` and adding a `#[cfg(test)]` module in `lib.rs`.

**Step 2: Run tests**

Run: `cargo test -p sema-lsp`
Expected: all tests pass

**Step 3: Commit**

```bash
git add crates/sema-lsp/tests/
git commit -m "test(lsp): integration tests for diagnostics and completion"
```

---

## Task 7: Update editor configs for LSP

**Files:**
- Modify: `editors/vscode/sema/package.json` (basic LSP config for future extension.ts)
- Create: `editors/helix/languages.toml` (or update if exists)
- Update docs: `website/docs/cli.md` (add `sema lsp` command)

**Step 1: Add Helix LSP config**

Check if `editors/helix/languages.toml` exists. If not, create it:

```toml
[[language]]
name = "sema"
scope = "source.sema"
file-types = ["sema"]
roots = ["sema.toml"]
comment-token = ";"
indent = { tab-width = 2, unit = "  " }
language-servers = ["sema-lsp"]

[language-server.sema-lsp]
command = "sema"
args = ["lsp"]
```

**Step 2: Add Neovim LSP config example**

Create `editors/neovim/lsp.lua`:

```lua
-- Sema LSP configuration for Neovim (nvim-lspconfig)
-- Add to your Neovim config or init.lua

local lspconfig = require('lspconfig')
local configs = require('lspconfig.configs')

if not configs.sema then
  configs.sema = {
    default_config = {
      cmd = { 'sema', 'lsp' },
      filetypes = { 'sema' },
      root_dir = lspconfig.util.root_pattern('sema.toml', '.git'),
    },
  }
end

lspconfig.sema.setup({})
```

**Step 3: Update CLI docs**

Add `sema lsp` to `website/docs/cli.md`.

**Step 4: Commit**

```bash
git add editors/ website/docs/cli.md
git commit -m "docs: add editor LSP configs for Helix, Neovim"
```

---

## Task 8: Verify end-to-end

**Step 1: Build release**

Run: `cargo build --release`

**Step 2: Manual smoke test with Helix or VS Code**

1. Open a `.sema` file
2. Introduce a syntax error (unclosed paren) — verify red squiggle appears
3. Fix the error — verify squiggle disappears
4. Type `def` — verify completions for `define`, `defun`, `defmacro`
5. Type `string/` — verify builtin string functions appear

**Step 3: Run full test suite**

Run: `cargo test`
Expected: all tests pass, including new `sema-lsp` tests

**Step 4: Final commit**

```bash
git add -A
git commit -m "feat(lsp): Phase 1 (parse diagnostics) + Phase 2 (completion) complete"
```

---

## Implementation Notes

### `SemaError` span access

The `SemaError::span()` method returns `Option<&Span>`. For `Reader` errors, the span is always present. For `WithContext` / `WithTrace` wrappers, it delegates to the inner error. Reference: `crates/sema-core/src/error.rs`.

### Builtin name collection

`Env.bindings` is `Rc<RefCell<SpurMap<Spur, Value>>>`. To get all binding names, borrow the map and resolve each `Spur` via `sema_core::resolve(spur)`. The parent chain contains builtins; walk it if needed, but the top-level global env (from `Interpreter::new_with_sandbox`) already has all stdlib registered directly.

### `as_symbol()` returns `Option<String>`

`Value::as_symbol()` returns `Option<String>` (not `&str`). This is fine for completion since we're comparing prefixes.

### `defn` handling

The design doc mentions `defun` but Sema also uses `defn` (which is actually the canonical form for named functions with optional docstrings). The completion code should handle both `defun` and `defn`.
