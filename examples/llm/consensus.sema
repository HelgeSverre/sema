;; consensus.sema — Multi-Model Consensus
;;
;; Forks a question to multiple LLM providers, collects their responses,
;; then synthesizes a "best of all worlds" answer.
;;
;; Usage:
;;   sema examples/llm/consensus.sema -- "What is the best way to handle errors in Rust?"
;;
;; Requires at least 2 of: ANTHROPIC_API_KEY, OPENAI_API_KEY, GEMINI_API_KEY
;; The synthesizer uses whichever provider was configured first (default).

(define provider (llm/auto-configure))
(when (nil? provider)
  (println-error "Error: Set at least 2 API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY, GEMINI_API_KEY)")
  (exit 1))

;; ── Parse args ──

(define (script-args)
  (let loop ((args (sys/args)) (found #f))
    (cond
      ((null? args) '())
      (found (cons (car args) (loop (cdr args) #t)))
      ((= (car args) "--") (loop (cdr args) #t))
      (else (loop (cdr args) #f)))))

(define args (script-args))

(when (null? args)
  (println-error "Usage: sema examples/llm/consensus.sema -- \"your question here\"")
  (exit 1))

(define question (string/join args " "))

;; ── Discover available providers ──

(define available-providers (llm/list-providers))

;; Each entry: {:provider :keyword :model "model-name" :label "display name"}
(define provider-configs
  (list
    {:provider :anthropic :model "claude-sonnet-4-20250514"     :label "Claude Sonnet"}
    {:provider :openai    :model "gpt-4.1"                     :label "GPT-4.1"}
    {:provider :gemini    :model "gemini-2.5-flash"             :label "Gemini 2.5 Flash"}
    {:provider :groq      :model "llama-3.3-70b-versatile"     :label "Llama 3.3 70B (Groq)"}
    {:provider :xai       :model "grok-3-mini-fast"            :label "Grok 3 Mini"}
    {:provider :mistral   :model "mistral-small-latest"        :label "Mistral Small"}))

;; Filter to only configured providers
(define active-configs
  (filter
    (fn (cfg) (any (fn (p) (= p (:provider cfg))) available-providers))
    provider-configs))

(when (< (length active-configs) 2)
  (println-error (format "Need at least 2 providers, found ~a: ~a"
    (length active-configs)
    (map (fn (c) (:label c)) active-configs)))
  (println-error "Set more API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY, GEMINI_API_KEY, etc.)")
  (exit 1))

;; ── Ask each provider ──

(println-error "")
(println-error (term/style "  Consensus Query" :bold))
(println-error (term/dim (format "  \"~a\"" question)))
(println-error (term/dim (format "  Asking ~a providers..." (length active-configs))))
(println-error "")

(define system-prompt
  "You are a knowledgeable expert. Give a clear, thorough answer. Be specific and practical. If the question is about code, include examples.")

(define (ask-provider cfg)
  "Switch to a provider, ask the question, return {:label ... :response ...}."
  (let ((label (:label cfg))
        (provider-kw (:provider cfg))
        (model (:model cfg)))
    (println-error (term/dim (format "  ⟳ Asking ~a (~a)..." label model)))
    (let ((start (time-ms)))
      (try
        (begin
          (llm/set-default provider-kw)
          (let* ((response (llm/complete question
                   {:model model :max-tokens 1500 :system system-prompt}))
                 (elapsed (- (time-ms) start)))
            (println-error (format "  ~a ~a ~a"
              (term/green "✔")
              (term/style label :bold)
              (term/dim (format "(~as)" (/ elapsed 1000)))))
            {:label label :response response :error #f}))
        (catch e
          (let ((elapsed (- (time-ms) start)))
            (println-error (format "  ~a ~a ~a"
              (term/red "✘")
              label
              (term/dim (format "~a" (get e :message (str e))))))
            {:label label :response "" :error #t}))))))

(define results (map ask-provider active-configs))

;; Filter out errors
(define successful (filter (fn (r) (not (:error r))) results))

(when (< (length successful) 2)
  (println-error "")
  (println-error (term/red "  Too many providers failed. Need at least 2 successful responses."))
  (exit 1))

;; ── Synthesize ──

(println-error "")
(println-error (term/dim (format "  ⟳ Synthesizing ~a responses..." (length successful))))

;; Switch back to the first configured provider for synthesis
(llm/set-default (:provider (car active-configs)))

(define synthesis-prompt
  (string-append
    "You received responses from multiple AI models to the same question.\n\n"
    "## Question\n\n" question "\n\n"
    "## Responses\n\n"
    (string/join
      (map (fn (r)
        (format "### ~a\n\n~a\n" (:label r) (:response r)))
        successful)
      "\n")
    "\n## Your Task\n\n"
    "Synthesize the best answer by combining the strongest insights from each response. "
    "Where the models agree, state the consensus confidently. "
    "Where they disagree, explain the trade-offs. "
    "If one model has a clearly better insight, highlight it. "
    "Be practical and specific. Include code examples if any model provided good ones.\n\n"
    "Do NOT list the models or attribute points to specific models — "
    "just present the unified best answer as if it were your own."))

(define synthesis
  (llm/complete synthesis-prompt
    {:max-tokens 3000 :temperature 0.3}))

(println-error (format "  ~a ~a" (term/green "✔") (term/style "Synthesis complete" :bold)))

;; ── Output ──

(println "")
(println synthesis)
(println "")

;; Show which models contributed
(println-error (term/dim (format "  Models consulted: ~a"
  (string/join (map (fn (r) (:label r)) successful) ", "))))
(println-error "")
