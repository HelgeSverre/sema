;; test-batch.sema â€” Test batch/parallel LLM completions
;; Requires: ANTHROPIC_API_KEY or OPENAI_API_KEY environment variable
;; Usage: cargo run -- examples/llm/test-batch.sema

(llm/auto-configure)

;; 1. Simple batch with string prompts
(println "=== Test 1: llm/batch (string prompts) ===")
(define answers
  (llm/batch (list "Say just: alpha" "Say just: beta" "Say just: gamma")))
(println "Results:" answers)

;; 2. Batch with options
(println "\n=== Test 2: llm/batch with options ===")
(define answers2
  (llm/batch
    (list "What is 1+1? Reply with just the number."
      "What is 2+2? Reply with just the number."
      "What is 3+3? Reply with just the number.")
    {:max-tokens 10}))
(println "Results:" answers2)

;; 3. Session usage after batch
(println "\n=== Session Usage ===")
(println (llm/session-usage))

(println "\nBatch tests complete!")
